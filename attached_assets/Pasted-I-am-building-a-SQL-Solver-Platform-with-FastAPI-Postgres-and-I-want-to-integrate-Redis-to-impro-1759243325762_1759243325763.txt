I am building a SQL Solver Platform (with FastAPI + Postgres) and I want to integrate Redis to improve performance and scalability.

🔹 Redis Use-Cases to Implement
1. Job Queue for SQL Submissions

When a user submits a SQL solution:

Push job into Redis queue (LPUSH problems:queue).

Job format (JSON):

{
  "job_id": "uuid123",
  "user_id": 42,
  "problem_id": 103,
  "sql": "SELECT dept, COUNT(*) FROM employees GROUP BY dept"
}


Worker consumes jobs using BRPOP problems:queue.

While processing, mark job in Redis:

HSET problems:processing:uuid123 status "running" user_id 42 problem_id 103


Once done:

Store result in Redis with TTL 5 minutes:

SETEX problems:result:uuid123 300 '{"status":"success","rows":10}'


Persist permanent record into Postgres submissions table.

✅ Expected: Generate FastAPI endpoint for /problems/submit and worker code for consuming jobs.

2. Result Caching

Before executing SQL, check if Redis has cached result for (user_id, problem_id).

GET cache:result:{user_id}:{problem_id}


If exists → return cached result.

If not, run SQL → store result in Redis for 5–10 min TTL.

SETEX cache:result:42:103 600 '{"status":"success","rows":10}'


✅ Expected: Add caching logic in submission workflow.

3. Leaderboards

Track number of solved problems per user using Redis Sorted Sets.

ZINCRBY leaderboard:global 1 user:42
ZINCRBY leaderboard:topic:joins 1 user:42


Fetch top 10 users globally:

ZREVRANGE leaderboard:global 0 9 WITHSCORES


Fetch user rank:

ZREVRANK leaderboard:global user:42


✅ Expected: Generate FastAPI endpoints:

/leaderboard/global

/leaderboard/topic/{topic}

/leaderboard/user/{id}

🔹 Postgres Schema (SQLAlchemy Models)

Please generate models for:

Users

id, username, email, created_at

Submissions

id, user_id, problem_id, sql_query, status, rows_returned, created_at

🔹 Tech Stack

Backend: FastAPI (Python)

Database: Postgres (Neon)

Cache/Queue: Redis (Upstash or Docker local)

ORM: SQLAlchemy + Alembic

🔹 Expected Output

FastAPI routes:

/problems/submit (enqueue + caching)

/problems/result/{job_id} (fetch result from Redis → fallback to Postgres)

/leaderboard/global (top N users)

/leaderboard/topic/{topic} (topic-specific leaderboard)

/leaderboard/user/{id} (user rank + score)

Worker script:

Consumes from problems:queue

Executes query

Stores results in Redis + Postgres

Example Redis commands with Python redis-py client.

🔹 Example Workflows
📝 SQL Submission Flow
User → FastAPI (/problems/submit)
   → Redis (LPUSH problems:queue)
   → Worker (BRPOP queue)
   → Executes SQL
   → SETEX problems:result:{id}
   → INSERT INTO Postgres (submissions)
User → FastAPI (/problems/result/{id})
   → GET Redis (result cache) → fallback to Postgres

🏆 Leaderboard Flow
User solves problem
   → Redis (ZINCRBY leaderboard:global 1 user:{id})
   → Redis (ZINCRBY leaderboard:topic:{topic} 1 user:{id})
Leaderboard endpoint
   → ZREVRANGE leaderboard:global 0 9 WITHSCORES
   → ZREVRANK leaderboard:global user:{id}


✅ Please generate:

FastAPI backend code with Redis + Postgres integrated.

SQLAlchemy models for Postgres tables.

Redis key usage examples.

Worker script for queue consumption.

Clear comments for each step.